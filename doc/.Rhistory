install.packages(c("caret", "R.matlab"))
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("EBImage")){
source("https://bioconductor.org/install")
biocLite("EBImage")
}
if(!require("EBImage")){
source("https://bioconductor.org/install/")
biocLite("EBImage")
}
if(!require("EBImage")){
source("https://bioconductor.org/install")
biocLite("EBImage")
}
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
set.seed(0)
setwd("/Users/rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/doc")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
k = c(5,11,21,31,41,51)
model_labels = paste("KNN with K =", k)
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
n_files <- length(list.files(train_image_dir))
image_list <- list()
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
for(i in 1:100){
image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
View(fiducial_pt_list)
fiducial_pt_list[[1]]
?prcomp
fiducial_pt_list.pca <- prcomp(fiducial_pt_list, scale. = T)
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}
View(dat_test)
feature.pca <- prcomp(dat_train, scale. = T)
View(dat_train)
class(dat_train)
colMeans(dat_train)
colMeans(dat_train[,1])
head(dat_train[,1])
dat_train[,1]
is.numeric(dat_train)
is.character(dat_train)
attr(dat_train)
?attr
attr(dat_train, class)
attr(dat_train, "class")
typeof(dat_train)
View(dat_test)
dat_train.new <- as.data.frame(dat_train)
typeof(dat_train.new)
feature.pca <- prcomp(dat_train.new, scale. = T)
dat_train.new <- as.numeric(dat_train)
dat_train.new <- unlist(dat_train)
dim(dat_train.new)
dat_train.new[6007]
head(dat_train.new)
dat_train.new
typeof(dat_train.new)
class(dat_train.new)
dat_train.new <- matrix(unlist(dat_train))
View(dat_train.new)
dat_train.new <- as.data.frame(unlist(dat_train))
View(dat_train.new)
dat_train[1,]
dat_train[,-1]
typeof(dat_train[])
typeof(dat_train[[]])
dat_train.new <- lapply(dat_train, as.numeric)
View(dat_train.new)
feature.pca <- prcomp(dat_train.new, scale. = T)
View(dat_train.new)
dat_train.new <- as.data.frame(dat_train.new)
View(dat_train.new)
typeof(dat_train.new)
class(dat_train.new[1])
class(dat_train[1])
typeof(dat_train[1])
View(dat_train)
dat_train.new <- head(unlist(dat_train))
dat_train.new
dat_train.new <- unlist(dat_train)
dat_train.new
as.numeric(dat_train[1])
dat_train.new <- as.numeric(dat_train[[1]])
dat_train.new <- as.numeric(dat_train[[1,]])
dat_train.new <- as.numeric(dat_train[[,1]])
View(dat_train)
library(purrr)
ncol(dat_train)
matrix(NULL)
matrix(NA)
dat_train.new <- matrix(0, ncol = ncol(dat_train) - 1, nrow = nrow(dat_train))
for (i in 1:(ncol(dat_train) - 1)) {
dat_train.new[,i] <- as.numeric(dat_train[[i]])
}
View(dat_train.new)
feature.pca <- prcomp(dat_train.new, scale. = T)
biplot(feature.pca)
screeplot(feature.pca)
summary(feature.pca)
sum(feature.pca$sdev)
sum((feature.pca$sdev[1:1000] / sum(feature.pca$sdev) )^2)
sum((feature.pca$sdev[1:2000] / sum(feature.pca$sdev) )^2)
sum((feature.pca$sdev[1:6000] / sum(feature.pca$sdev) )^2)
sum((feature.pca$sdev[1:6000])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev)^2)
(feature.pca$sdev)^2
sum((feature.pca$sdev)^2)
length(feature.pca$sde)
length(feature.pca$sdev)
sum((feature.pca$sdev[1:2000])^2)
sum((feature.pca$sdev[1:2000])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:1000])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:500])^2) / sum((feature.pca$sdev)^2)
knitr::opts_chunk$set(echo = TRUE)
## Load data
train.3 <- read.table("train_3.txt", header=FALSE, sep=",")
train.5 <- read.table("train_5.txt", header=FALSE, sep=",")
train.8 <- read.table("train_8.txt", header=FALSE, sep=",")
zip.test.all <- read.table("zip_test.txt", header=TRUE, sep=" ")
## Combine training data
zip.train <- rbind(train.3, train.5, train.8)
zip.train.l <- data.frame(zip.train, ZIP = rep(c(3,5,8),c(658, 556, 542)))
## Subset test data
colnames(zip.test.all) <- c("ZIP", colnames(zip.train))
zip.test <- zip.test.all[zip.test.all$ZIP %in% c(3, 5, 8),]
# Q1
##LDA on original 256 dim
library(MASS)
l <- lda(ZIP~., data = zip.train.l)
pred.test <- predict(l, zip.test[,-1])
## training error and test error
error.train <- sum(pred.train$class != zip.train.l[,257])/nrow(zip.train.l)
error.test <- sum(pred.test$class != zip.test[,1])/nrow(zip.test)
error.train
error.test
pred.train <- predict(l, zip.train.l[,1:256])
pred.test <- predict(l, zip.test[,-1])
## training error and test error
error.train <- sum(pred.train$class != zip.train.l[,257])/nrow(zip.train.l)
error.test <- sum(pred.test$class != zip.test[,1])/nrow(zip.test)
error.train
error.test
# Q2
## PCA to filter the first 49 components for training and test data
pca.train <- prcomp(zip.train, scale. = T)
pca.train
zip.train
View(dat_train.new)
head(feature.pca$rotation)
head(feature.pca$rotation[,1:10])
dat_train.new <- as.data.frame(dat_train.new)
feature.pca <- prcomp(dat_train.new, scale. = T)
View(dat_train.new)
head(feature.pca$rotation[,1:10])
length(feature.pca$sdev)
sum((feature.pca$sdev[1:500])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:300])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:100])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:500])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:50])^2) / sum((feature.pca$sdev)^2)
sum((feature.pca$sdev[1:10])^2) / sum((feature.pca$sdev)^2)
?cbind
dat_train[,6007]
## Combine pc_features with the emption index
dat_train_pca <- cbind(feature.pca$x[,1:500], dat_train[,6007])
View(dat_train_pca)
View(dat_train)
## Extract PC from test data
dat_test.new <- predict(feature.pca, dat_test[,1:(ncol(dat_train) - 1)])
## Extract PC from test data
dat_test.new <- dat_test
View(dat_train_pca)
View(dat_train)
colnames(dat_test.new) <- c(colnames(dat_train.new), "emotion_idx")
dat_test.new <- predict(feature.pca, dat_test.new[,1:(ncol(dat_train) - 1)])
dat_test.new
## Combine pc_features with the emption index
dat_test_pca <- data.frame(dat_test.new$x[,1:500], dat_test.new[,6007])
## Combine pc_features with the emption index
dat_test_pca <- data.frame(dat_test.new[,1:500], dat_test.new[,6007])
View(dat_test.new)
View(dat_test)
## Combine pc_features with the emption index
dat_test_pca <- data.frame(dat_test.new[,1:500], dat_test[,6007])
View(dat_test_pca)
## Combine pc_features with the emption index
dat_train_pca <- data.frame(feature.pca$x[,1:500], emotion_idx = dat_train[,6007])
## Combine pc_features with the emption index
dat_test_pca <- data.frame(dat_test.new[,1:500], emotion_idx = dat_test[,6007])
View(dat_test_pca)
View(dat_train_pca)
save(dat_train_pca, file="../output/feature_train_pca.RData")
save(dat_test_pca, file="../output/feature_test_pca.RData")
load("/Users/Rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/output/feature_train_pca.RData")
load("/Users/Rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/output/feature_test_pca.RData")
load("/Users/Rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if(!require("R.matlab")){
install.packages("R.matlab")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("dplyr")){
install.packages("dplyr")
}
if(!require("readxl")){
install.packages("readxl")
}
if(!require("ggplot2")){
install.packages("ggplot2")
}
if(!require("caret")){
install.packages("caret")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
set.seed(0)
setwd("/Users/rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/doc")
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
k = c(5,11,21,31,41,51)
model_labels = paste("KNN with K =", k)
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}
library(purrr)
## Convert dat_train to numeric data.frame
dat_train.new <- matrix(0, ncol = ncol(dat_train) - 1, nrow = nrow(dat_train))
for (i in 1:(ncol(dat_train) - 1)) {
dat_train.new[,i] <- as.numeric(dat_train[[i]])
}
## Convert dat_train to numeric data.frame
dat_train.new <- matrix(0, ncol = ncol(dat_train) - 1, nrow = nrow(dat_train))
load("/Users/Rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/output/feature_train.RData")
load("/Users/Rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/output/feature_test.RData")
## Convert dat_train to numeric data.frame
dat_train.new <- matrix(0, ncol = ncol(dat_train) - 1, nrow = nrow(dat_train))
for (i in 1:(ncol(dat_train) - 1)) {
dat_train.new[,i] <- as.numeric(dat_train[[i]])
}
dat_train.new <- as.data.frame(dat_train.new)
## PCA for training features
feature.pca <- prcomp(dat_train.new, scale. = T)
## PCA for training features
feature.pca <- prcomp(dat_train.new, scale. = T)
## The proportion of variance for first 500 PCs
sum((feature.pca$sdev[1:500])^2) / sum((feature.pca$sdev)^2)
## Combine pc_features with the emption index
dat_train_pca <- data.frame(feature.pca$x[,1:500], emotion_idx = dat_train[,6007])
screeplot(feature.pca)
sum((feature.pca$sdev)^2)
##############################################################
### Train a classification model with training pc features ###
##############################################################
library(e1071)
?svm
View(dat_train_pca)
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='linear')
model1
View(model1)
?fitted
pred <- fitted(model1)
table(pred, dat_train_pca[,501])
test.pred <- predict(model1,dat_test_pca[,1:500])
table(test.pred, dat_test_pca[,501])
sum(test.pred!=dat_test_pca[,501])/500
sum(test.pred==dat_test_pca[,501])/500
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='radial')
test.pred <- predict(model1,dat_test_pca[,1:500])
table(test.pred, dat_test_pca[,501])
sum(test.pred==dat_test_pca[,501])/500
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='polynomial', degree = 3)
test.pred <- predict(model1,dat_test_pca[,1:500])
#table(test.pred, dat_test_pca[,501])
sum(test.pred==dat_test_pca[,501])/500
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='polynomial', degree = 20)
test.pred <- predict(model1,dat_test_pca[,1:500])
#table(test.pred, dat_test_pca[,501])
sum(test.pred==dat_test_pca[,501])/500
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='linear')
plot(model1, dat_test_pca)
model.plot <- svm(emotion_idx~., data = dat_test_pca,type="C",kernel="linear")
plot(model.plot, dat_test_pca)
View(dat_test_pca)
?plot.svm
plot(model.plot, dat_test_pca, formula = c(1,2))
plot(model.plot, dat_test_pca, formula = c(PC1,PC2))
plot(model.plot, dat_test_pca, formula = c("PC1","PC2"))
plot(model.plot, dat_test_pca, PC1~PC2)
View(dat_train)
model1 <- svm(dat_train_pca[,1:500], dat_train_pca[,501],type='C',kernel='linear')
pred <- fitted(model1)
test.pred <- predict(model1,dat_test_pca[,1:500])
#table(test.pred, dat_test_pca[,501])
sum(test.pred==dat_test_pca[,501])/500
model2 <- svm(dat_train_pca[,1:6006], dat_train_pca[,6007],type='C',kernel='linear')
pred2 <- fitted(model2)
model2 <- svm(dat_train_[,1:6006], dat_train[,6007],type='C',kernel='linear')
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='linear')
pred2 <- fitted(model2)
test.pred2 <- predict(model2,dat_test_pca[,1:6006])
#table(test.pred, dat_test_pca[,501])
sum(test.pred2==dat_test[,6007])/500
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
sum(test.pred2==dat_test[,6007])/500
library(purrr)
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='radial')
pred2 <- fitted(model2)
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
svm
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='radial', gamma = 1)
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='radial', gamma = 0.01)
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='radial', gamma = 0.00001)
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='radial', gamma = 0.00000001)
pred2 <- fitted(model2)
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
### Original data
model2 <- svm(dat_train[,1:6006], dat_train[,6007],type='C',kernel='linear')
test.pred2 <- predict(model2,dat_test[,1:6006])
#table(test.pred, dat_test_pca[,501])
mean(test.pred2==dat_test$emotion_idx)
### Train the model with the entire training set using the selected model (model parameter) via cross-validation.
source("../lib/train_qda.R")
setwd("/Users/rachel/Documents/GitHub/Spring2020-Project3-ads-spring2020-project3-group9/doc")
### Train the model with the entire training set using the selected model (model parameter) via cross-validation.
source("../lib/train_qda.R")
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train_pca, par_best))
tm_train <- system.time(fit_train <- train(dat_train_pca))
?qda
qda_model <- qda(emotion_idx~., data = dat_train_pca)
library(MASS)
qda_model <- qda(emotion_idx~., data = dat_train_pca)
class(dat_train_pca[,501])
class(dat_train[,6007])
as.numeric(dat_train[,6007])
## Combine pc_features with the emption index
dat_train_pca <- data.frame(feature.pca$x[,1:500], emotion_idx = as.numeric(dat_train[,6007]))
class(dat_train_pca[,501])
qda_model <- qda(emotion_idx~., data = dat_train_pca)
class(dat_train_pca[,501])
## Combine pc_features with the emption index
dat_train_pca <- data.frame(feature.pca$x[,1:500], emotion_idx = as.double(dat_train[,6007]))
class(dat_train_pca[,501])
dat_train_pca[,501]
qda_model <- qda(emotion_idx~., data = dat_train_pca)
typeof(dat_train_pca[,501])
str(dat_train_pca)
summary(dat_train_pca)
str(dat_train_pca[,501])
summary(dat_train_pca[,501])
qda_model <- qda(emotion_idx~., data = dat_train_pca)
typeof(dat_train_pca[,501])
str(dat_train_pca[,501])
summary(dat_train_pca[,501])
qda(emotion_idx~., data = dat_train_pca)
